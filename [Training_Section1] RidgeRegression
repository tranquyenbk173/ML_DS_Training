{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"[Training_Section1] RidgeRegression","provenance":[],"mount_file_id":"16u-tS6A9YikINOKZpDpv8X40FZM2K7jV","authorship_tag":"ABX9TyPJ4SBhhmGY27BELrKtBBJM"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"feBflAPSIErc","colab_type":"code","outputId":"33a3b5b3-afbb-473a-b086-208733831953","executionInfo":{"status":"ok","timestamp":1587131513069,"user_tz":-420,"elapsed":1321,"user":{"displayName":"Quyen Tran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhoMMy50mqj9WbAat9Z4itNZ14utD-jBkhGuYfk=s64","userId":"15840549449197934767"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd /content/drive/My Drive/Colab Notebooks/DS_Lab/Data/"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Colab Notebooks/DS_Lab/Data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ELN4r6yn75xt","colab_type":"code","colab":{}},"source":["###Doc du lieu:\n","import csv\n","with open('death_rate.csv', 'w') as fileCSV:\n","  writer = csv.writer(fileCSV, delimiter = ',', quotechar = '\"', quoting = csv.QUOTE_MINIMAL)\n","\n","  with open('death_rate.txt', 'r') as fileTXT:\n","    for line in fileTXT:\n","      d_line = line.split()\n","      writer.writerow(d_line)\n","  fileTXT.close()\n","fileCSV.close()\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RfEDIlIeJECr","colab_type":"code","outputId":"e38acb7a-c0a0-4f81-ab14-35316947d661","executionInfo":{"status":"ok","timestamp":1587132539972,"user_tz":-420,"elapsed":1122,"user":{"displayName":"Quyen Tran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhoMMy50mqj9WbAat9Z4itNZ14utD-jBkhGuYfk=s64","userId":"15840549449197934767"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import pandas as pd\n","import numpy as np\n","data = pd.read_csv('death_rate.csv')\n","\n","X = data.drop(columns=['Index', 'Death_rate'])\n","y = data['Death_rate']\n","X = np.array(X)\n","y = np.array(y)\n","print(X.shape)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["(60, 15)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5rL3VEcgI_Mk","colab_type":"code","colab":{}},"source":["##Chuan hoa du lieu:\n","X_min = X.min(axis = 0)\n","X_max = X.max(axis = 0)\n","X_delta = X_max - X_min\n","X = (X-X_min)/X_delta\n","X = np.c_[np.ones((X.shape[0], 1)), X]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ES4s8OJqJ4Sc","colab_type":"code","colab":{}},"source":["###Trien khai mo hinh:\n","class RidgeRegression:\n","  def __init__(self):\n","    return\n","\n","  #FIT voi phep nhan ma tran:\n","  def fit(self, X_train, y_train, LAMBDA):\n","    w = np.linalg.pinv(X_train.T.dot(X_train) + LAMBDA*np.identity(X_train.shape[1])).dot(X_train.T).dot(y_train)\n","    return w\n","\n","  #FIT voi GD\n","  def fit_GD(self, X_train, y_train, LAMBDA, learning_rate, batch_size=20, epoch=50):\n","    w = np.random.randn(X_train.shape[1])\n","    last_loss = 10e8\n","  \n","    for i in range(epoch):\n","\n","      #xao tron\n","      ids = range(0, X.shape[0])\n","      ids = np.random.shuffle(ids)\n","      X_train = X_train[ids]\n","      y_train = y_train[ids]\n","\n","      #chia ra cac batch va huan luyen\n","      numOfBatch = X_train.shape[0]/batch_size\n","      for ib in numOfBatch:\n","        index = ib*batch_size\n","        Xb = X_train[index: index + batch_size]\n","        yb = y_train[index: index + batch_size]\n","        grad = Xb.T.dot(X.dot(w)-yb) + LAMBDA*w\n","        w -= learning_rate*grad\n","\n","      new_loss = self.LOSS(self.predict(X_train, w), y_train)\n","      if np.abs(new_loss - last_loss) < 1e-5:\n","        break\n","      last_loss = new_loss\n","\n","    return w\n","\n","  #Tinh ham loss\n","  def LOSS(self, y_pred, y_real):\n","    return 1./(y_real.shape[0])*np.linalg.norm(y_pred - y_real)**2\n","  \n","  #Du doan ket qua:\n","  def predict(self, X_pred, w):\n","    return X_pred.dot(w)\n","  #Cross-validation\n","  def cross_validation(self, X_train, y_train, num_folds, LAMBDA):\n","    #xao tron bo du lieu:\n","    ids = np.array(range(X_train.shape[0]))\n","    np.random.shuffle(ids) #cai nay tra ve None nha :)))) 17/4/20\n","    X_train = X_train[ids]\n","    y_train = y_train[ids]\n","    \n","    n = X_train.shape[0]\n","    \n","    #chia thanh cac fold:\n","    odd = n % num_folds\n","    num_each = n / num_folds\n","    valid_ids = np.split(ids[:(n - odd)], num_folds)\n","    valid_ids[-1] = np.append(valid_ids[-1], ids[n - odd:])\n","    train_ids = [[k for k in ids if k not in valid_ids[i]] for i in range(num_folds)]\n","\n","    #tim AvG_losss:\n","    avg_loss = 0\n","    for i in range(num_folds):\n","      train_X = X_train[train_ids[i]]\n","      train_y = y_train[train_ids[i]]\n","      valid_X = X_train[valid_ids[i]]\n","      valid_y = y_train[valid_ids[i]]\n","      w = self.fit(train_X, train_y, LAMBDA)\n","      y_pred = self.predict(valid_X, w)\n","      loss = self.LOSS(y_pred, valid_y)\n","      avg_loss += loss\n","    return avg_loss/num_folds\n","\n","  #tim lambda tot nhat trong 1 mien cho truoc, tra ve gia tri lambda tot nhat va gia tri loss t/ung:\n","  def range_scan(self, L_values, min_loss, X_train, y_train):\n","    for L in L_values:\n","      loss = self.cross_validation(X_train = X_train, y_train = y_train, \n","                                   num_folds=5, LAMBDA = L)\n","      if loss < min_loss:\n","        min_loss = loss\n","        best_L = L\n","    return min_loss, best_L\n","  \n","  #Tim lambda tot nhat:\n","  def get_best_lambda(self, X_train, y_train):\n","    L_values = range(50) #khoi tao bo gia tri lambda ban dau\n","    min_loss, best_L = self.range_scan(L_values, min_loss = 10e8, X_train = X_train, y_train = y_train) \n","       #buoc nay tim best_L trong 1 mien cho truoc, sau do tim best_L trong khoang hep hon tu gia tri vua tim duoc\n","    C = range(max(0, best_L-1)*1000, (best_L+1)*1000, 1)\n","    L_values = [k*1./1000 for k in C]\n","\n","    #tim best_L chinh xac hon: \n","    min_loss, best_L = model.range_scan(L_values, min_loss, X_train, y_train)\n","\n","    return best_L\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WhOg1Yy-Yf88","colab_type":"code","outputId":"57a60537-8682-4374-ec70-34c62c92d8db","executionInfo":{"status":"ok","timestamp":1587134216103,"user_tz":-420,"elapsed":3764,"user":{"displayName":"Quyen Tran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhoMMy50mqj9WbAat9Z4itNZ14utD-jBkhGuYfk=s64","userId":"15840549449197934767"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["#Trien khai:\n","\n","if __name__ == '__main__':\n","  #Lay du lieu va chuan hoa <da lam>\n","  X_train = X[:50]\n","  y_train = y[:50]\n","  X_test = X[50:]\n","  y_test = y[50:]\n","\n","  model = RidgeRegression()\n","  #Tim lambda tot nhat:\n","  LAMBDA = model.get_best_lambda(X_train = X_train, y_train = y_train)\n","  print(\"The best LAMBDA: \", LAMBDA)\n","  \n","  #Huan luyen mo hinh:\n","  w = model.fit(X_train, y_train, LAMBDA)\n","\n","  #Du doan tren tap test:\n","  y_pred = model.predict(X_test, w)\n","\n","  #Loss thu duocj:\n","  print(\"Loss: \", model.LOSS(y_test, y_pred))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["The best LAMBDA:  0.025\n","Loss:  1412.7984615709365\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eIMYmNlBLuBV","colab_type":"code","outputId":"f858a175-348c-4516-ee0a-fd837d1c75c5","executionInfo":{"status":"ok","timestamp":1587134223427,"user_tz":-420,"elapsed":1336,"user":{"displayName":"Quyen Tran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhoMMy50mqj9WbAat9Z4itNZ14utD-jBkhGuYfk=s64","userId":"15840549449197934767"}},"colab":{"base_uri":"https://localhost:8080/","height":85}},"source":["#Thu nghiem lai voi thu vien\n","from sklearn.linear_model import LinearRegression\n","\n","model1 = LinearRegression()\n","model1.fit(X_train, y_train)\n","y_pred = model1.predict(X_test)\n","\n","N = y_pred.shape[0]\n","print(1./N * np.linalg.norm(y_pred-y_test)**2)\n","print(X_train[0])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["1584.5425212262771\n","[1.         0.52       0.21126761 0.36363636 0.40322581 0.68852459\n"," 0.72727273 0.61506276 0.21821264 0.21220159 0.33976834 0.13529412\n"," 0.0309119  0.04402516 0.20938628 0.6       ]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BVaV8PEoTgTW","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"7950d4d3-37d7-498a-f5bd-e696d52d4010","executionInfo":{"status":"ok","timestamp":1587249081967,"user_tz":-420,"elapsed":1085,"user":{"displayName":"Quyen Tran","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhoMMy50mqj9WbAat9Z4itNZ14utD-jBkhGuYfk=s64","userId":"15840549449197934767"}}},"source":["a = [(1, 2), (3, 4), (5, 6)]\n","b = dict(a)\n","b"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{1: 2, 3: 4, 5: 6}"]},"metadata":{"tags":[]},"execution_count":13}]}]}